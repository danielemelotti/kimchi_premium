{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries - YT: Multiple Regression Analysis in Python | Part 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the database\n",
    "df = pd.read_excel(r'C:\\Users\\danie\\Documents\\IMBA\\SEMESTER 1\\4. Research Methods & Data Analysis\\3. Final report\\Excel\\FACTORS_x_Reg.xlsx', sheet_name = 'Kraken' )\n",
    "dg = pd.read_excel(r'C:\\Users\\danie\\Documents\\IMBA\\SEMESTER 1\\4. Research Methods & Data Analysis\\3. Final report\\Excel\\FACTORS_x_Reg.xlsx', sheet_name = 'Upbit' )\n",
    "df = df.dropna(how = \"any\")\n",
    "dg = dg.dropna(how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index equal to the Date column\n",
    "df.index = df['Date']\n",
    "dg.index = dg['Date']\n",
    "\n",
    "df = df.drop('Date', axis = 1)\n",
    "dg = dg.drop('Date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data type of the data frame\n",
    "df = df.astype(float)\n",
    "dg = dg.astype(float)\n",
    "\n",
    "# Check for nulls\n",
    "display (\"-\"*100)\n",
    "display(df.head())\n",
    "display(dg.head())\n",
    "\n",
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Mp(EW)', 'Mp(VW)', 'Size_1(EW)', 'Size_1(VW)', 'Size_2(EW)', 'Size_2(VW)', 'Size_3(EW)', 'Size_3(VW)', 'Mom_1(EW)', 'Mom_1(VW)', 'Mom_2(EW)', 'Mom_2(VW)', 'Mom_3(EW)', 'Mom_3(VW)', 'Illiq_1(EW)', 'Illiq_1(VW)', 'Illiq_2(EW)', 'Illiq_2(VW)', 'Illiq_3(EW)'], axis = 1)\n",
    "\n",
    "# Define input variable and output variable\n",
    "X = df.drop('Illiq_3(VW)', axis = 1)\n",
    "Y = df[['Illiq_3(VW)']]\n",
    "\n",
    "# Split dataset into training and testing portion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 1)\n",
    "\n",
    "# Create an instance of our model\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4\n",
    "# Grab the intercept and the coefficients\n",
    "intercept = regression_model.intercept_[0]\n",
    "coef = regression_model.coef_[0]\n",
    "\n",
    "print('The intercept of our model is {:.4}'.format(intercept))\n",
    "print('-' * 100)\n",
    "\n",
    "# Loop through the dictionary and print the data\n",
    "for cf in zip(X.columns, regression_model.coef_[0]):\n",
    "    print('The coefficient for {} is {:.2}'.format(cf[0], cf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple predictions\n",
    "y_predict = regression_model.predict(X_test)\n",
    "\n",
    "# Show the first five\n",
    "y_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "# Define our inputs\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "\n",
    "# Create an OLS model\n",
    "model = sm.OLS(Y, X2)\n",
    "\n",
    "# Fit the data\n",
    "est = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running White Test (Heteroscedasticity)\n",
    "_, pval, _, f_pval = diag.het_white(est.resid, est.model.exog)\n",
    "print(pval, f_pval)\n",
    "print('-' * 100)\n",
    "\n",
    "#print the results of the test\n",
    "if pval > 0.05:\n",
    "    print(\"For the White's test\")\n",
    "    print(\"The p-value was (:.4)\".format(pval))\n",
    "    print(\"We fail to reject the null hypothesis, so there is no heteroscedasticity. \\n\")\n",
    "else:\n",
    "    print(\"For the White's test\")\n",
    "    print(\"The p-value was (:.4)\".format(pval))\n",
    "    print(\"We reject the null hypothesis, so there is heteroscedasticity. \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the lag\n",
    "lag = min(10, (len(X)// 5))\n",
    "print('The number of lags will be ()'.format(lag))\n",
    "print('-' * 100)\n",
    "\n",
    "# Perform the Ljung-Box test\n",
    "test_results = diag.acorr_ljungbox(est.resid, lags = lag)\n",
    "\n",
    "print(test_results)\n",
    "# Grab the p-values and test the statistics\n",
    "ibvalue, p_val = test_results\n",
    "\n",
    "# Print the results of the test\n",
    "if min(p_val) > 0.05:\n",
    "    print('The lowest p-value found was {:.4}'.format(min(p_val)))\n",
    "    print('We fail to reject the null hypothesis, so there is no autocorrelation.')\n",
    "    print('-' * 100)\n",
    "else:\n",
    "    print('The lowest p-value found was {:.4}'.format(min(p_val)))\n",
    "    print('We reject the null hypothesis, so there is autocorrelation.')\n",
    "    print('-' * 100)\n",
    "\n",
    "# Plot autocorrelation\n",
    "sm.graphics.tsa.plot_acf(est.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 5\n",
    "\n",
    "# Check for the normality of the residuals\n",
    "sm.qqplot(est.resid, line = 's')\n",
    "pylab.show()\n",
    "\n",
    "# Check that the mean of the residuals is approximately 0\n",
    "mean_residuals = sum(est.resid) / len(est.resid)\n",
    "mean_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
